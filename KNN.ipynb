{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFwj2EUujMRk"
      },
      "outputs": [],
      "source": [
        "# For data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# For model training and evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.model_selection as ms\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# For visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import Image\n",
        "import pydotplus\n",
        "%matplotlib inline\n",
        "\n",
        "# For Google Colab integration\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Read the Data and Check the Stats"
      ],
      "metadata": {
        "id": "sTcqgOnWJKXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import data as dataframe\n",
        "file_path = '/content/drive/MyDrive/Infor648/Data/churn.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# calling head() method\n",
        "df.head()"
      ],
      "metadata": {
        "id": "GUY85F_tjox_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_summary = df.describe()\n",
        "df_summary"
      ],
      "metadata": {
        "id": "8JBW0Df5JRIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove Rows with a Missing Value"
      ],
      "metadata": {
        "id": "f-0XsFUYJCU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[[\"Gender\", \"Age\", \"Married\", \"Number of Dependents\", \"Tenure in Months\", \"Monthly Charge\", \"Total Charges\", \"Total Refunds\" ,\"Total Revenue\", \"Customer Status\"]]"
      ],
      "metadata": {
        "id": "D6-yuUjcIe7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df.isna().sum()) ##check missing value\n",
        "#df = df.dropna() ##drop missing value"
      ],
      "metadata": {
        "id": "ONSBwiF-vLqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna() ##drop missing value"
      ],
      "metadata": {
        "id": "eU0jakecV9jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df.isna().sum()) ##recheck missing value again"
      ],
      "metadata": {
        "id": "i5iBDXMRvVwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#check how many categorical/numeric variables we have"
      ],
      "metadata": {
        "id": "M6MHybhPJUda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numeric Variables\n",
        "numeric_variables = [col for col in df.columns if df[col].dtype != \"object\" and col not in \"Customer Status\"] ##exclude our target variable: customer status\n",
        "numeric_variables"
      ],
      "metadata": {
        "id": "9hXueKxIvdPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_variables = [col for col in df.columns if df[col].dtype == \"O\" and col != \"Customer Status\"]  ###exclude our target: \"Customer Status\"\n",
        "categorical_variables"
      ],
      "metadata": {
        "id": "nJuOLI3UveyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['Gender', 'Married']]"
      ],
      "metadata": {
        "id": "OTFk7wFwW4tX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Select the variables we are interested in"
      ],
      "metadata": {
        "id": "isfOy3ezJdAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub = df[[\"Gender\", \"Age\", \"Married\", \"Number of Dependents\", \"Tenure in Months\", \"Monthly Charge\", \"Total Charges\", \"Total Refunds\" ,\"Total Revenue\", \"Customer Status\"]]"
      ],
      "metadata": {
        "id": "v7awZMmlvlYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encode our categorical data"
      ],
      "metadata": {
        "id": "2aElO6StJiSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##encode categorical data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df_sub['Gender'] = label_encoder.fit_transform(df_sub['Gender'])\n",
        "mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "\n",
        "\n",
        "#Print out what we encoded for gender\n",
        "print(\"Gender Encoding:\")\n",
        "print(mapping)"
      ],
      "metadata": {
        "id": "vXYuBzpOvp7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub['Married'] = label_encoder.fit_transform(df_sub['Married'])\n",
        "mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "\n",
        "\n",
        "#prints out what we encoded for married\n",
        "print(\"Married Encoding:\")\n",
        "print(mapping)"
      ],
      "metadata": {
        "id": "chXd9BDUvsWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now encode our target variable"
      ],
      "metadata": {
        "id": "Q4nD4oDWJltE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_sub['Customer Status'].value_counts())\n",
        "##Our target variable is a categorical variable"
      ],
      "metadata": {
        "id": "wGUEPaZXwDz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####We are only interested in why people stayed and churned\n",
        "df_sub = df_sub[df_sub['Customer Status'] !='Joined'] # we drop all the new customers\n",
        "\n",
        "####Encode our target variable\n",
        "target_label_encoder = LabelEncoder()\n",
        "df_sub['Customer Status'] = target_label_encoder.fit_transform(df_sub['Customer Status'])\n",
        "\n",
        "\n",
        "##display the stats after encoding\n",
        "display(df_sub['Customer Status'].value_counts())\n",
        "mapping = dict(zip(target_label_encoder.classes_, target_label_encoder.transform(target_label_encoder.classes_)))\n",
        "print(mapping)"
      ],
      "metadata": {
        "id": "TQzjatA-wF38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define features (X) and target (y)"
      ],
      "metadata": {
        "id": "FZaVfpDRJtyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X = df_sub.drop('Customer Status', axis=1)  # Drop the target column to get independent variables\n",
        "y = df_sub['Customer Status']  # Select the target column directly as our y\n",
        "\n",
        "feature_names = X.columns.tolist()\n",
        "\n",
        "\n",
        "\n",
        "class_names = target_label_encoder.inverse_transform(np.arange(len(target_label_encoder.classes_)))\n",
        "\n",
        "##print out the features we selected for predictions and our classification target\n",
        "print(\"features:\",feature_names)\n",
        "print(\"Classes:\", class_names)\n"
      ],
      "metadata": {
        "id": "SQIOAN0awfUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check our feature scale\n",
        "X"
      ],
      "metadata": {
        "id": "__ZQDsfDw1Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Standardizing the independent variable features to ensure they have the same scale"
      ],
      "metadata": {
        "id": "BDvvleGNJ14K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the independent variables\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and testing sets (70% training, 30% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
      ],
      "metadata": {
        "id": "JgnWVRl2wtwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train our KNN model"
      ],
      "metadata": {
        "id": "QvJIZwqfKLND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###the n we choose is 3 and the distance metric we choose is euclidean\n",
        "knn_model = KNeighborsClassifier(n_neighbors = 3, metric = 'euclidean')\n",
        "knn_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = knn_model.predict(X_test)\n",
        "\n",
        "#check our trained knn\n",
        "knn_model"
      ],
      "metadata": {
        "id": "6OQ9DyINxAwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate our KNN model"
      ],
      "metadata": {
        "id": "oNuFEIAtKnkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Create a DataFrame for evaluation metrics\n",
        "evaluation_metrics = pd.DataFrame({\n",
        "    \"Evaluation Metric\": [\"Train Accuracy\", \"Test Accuracy\", \"Recall\", \"Precision\", \"F1 Score\"],\n",
        "    \"Value\": [\n",
        "        knn_model.score(X_train, y_train),\n",
        "        accuracy_score(y_test, y_pred),\n",
        "        recall_score(y_test, y_pred),\n",
        "        precision_score(y_test, y_pred),\n",
        "        f1_score(y_test, y_pred)\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Display the DataFrame\n",
        "evaluation_metrics\n"
      ],
      "metadata": {
        "id": "XQ8vmA05ujFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))  # Adjust figure size if needed\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.ylabel('True Class')\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.title('Confusion Matrix for KNN Model')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o4NJZrvnsarV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.classifier import ClassificationReport\n",
        "\n",
        "# Create the classification report visualizer for the k-NN model\n",
        "visualizer = ClassificationReport(knn_model, classes=class_names, support=False, title=\"KNN Classifier Evaluation\")\n",
        "\n",
        "\n",
        "visualizer.fit(X_train, y_train)\n",
        "visualizer.score(X_test, y_test)\n",
        "\n",
        "\n",
        "# Display the plot\n",
        "visualizer.show()\n"
      ],
      "metadata": {
        "id": "JiMsvpvEyB04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performing cross-validation on the entire dataset to provide a general evaluation of the model's performance"
      ],
      "metadata": {
        "id": "o2qKmYFhLjeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
        "\n",
        "#our original model n = 3 and distance metric is euclidean\n",
        "CV_model = KNeighborsClassifier(n_neighbors=3,metric = 'euclidean')\n",
        "\n",
        "# Cross-validate with 10 folds\n",
        "y_pred_cross = cross_val_predict(CV_model, X, y, cv=10)\n",
        "\n",
        "# Compute evaluation metrics for cross-validation\n",
        "accuracy_cv = accuracy_score(y, y_pred_cross)\n",
        "recall_cv = recall_score(y, y_pred_cross)\n",
        "precision_cv = precision_score(y, y_pred_cross)\n",
        "f1_cv = f1_score(y, y_pred_cross)\n",
        "matrix_cv = confusion_matrix(y, y_pred_cross)\n",
        "\n",
        "\n",
        "# Create DataFrame for evaluation metrics with cross-validation\n",
        "evaluation_metrics_with_cv = pd.DataFrame({\n",
        "    \"Evaluation Metric_CV\": [\"Accuracy\", \"Recall\", \"Precision\", \"F1 Score\"],\n",
        "    \"Value\": [\n",
        "        accuracy_cv,\n",
        "        recall_cv,\n",
        "        precision_cv,\n",
        "        f1_cv\n",
        "    ]\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Performance Metrics With Cross-Validation:\")\n",
        "display(evaluation_metrics_with_cv)\n",
        "print('\\nConfusion Matrix with CV:\\n', matrix_cv)\n",
        "\n",
        "print(\"\\nPerformance Metrics Without Cross-Validation:\")\n",
        "display(evaluation_metrics)\n",
        "print('\\nConfusion Matrix Without CV:\\n', conf_matrix)\n"
      ],
      "metadata": {
        "id": "WP0yh5A11DD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Note: k-NN does not provide feature importance because it relies purely on distance calculations between data points.\n",
        "\n",
        "#### Unlike decision trees, k-NN does not use feature splits or calculate information gain to make predictions.\n"
      ],
      "metadata": {
        "id": "ZRxZr354Ofm5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameter Fine-tuning (choosing the best n)"
      ],
      "metadata": {
        "id": "eJmT1Ei6Nd9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_neighbors_range = range(1, 16) #Here is the n range we would like to test; you can make adjustments here\n",
        "train_accuracies = []\n",
        "cv_test_accuracies = []\n",
        "\n",
        "# Loop over different values of n_neighbors\n",
        "for n in n_neighbors_range:\n",
        "    hyperFT_model = KNeighborsClassifier(n_neighbors=n,metric = 'euclidean')\n",
        "\n",
        "    # Fit the model on the training set\n",
        "    hyperFT_model.fit(X_train, y_train)\n",
        "\n",
        "    # Calculate training accuracy\n",
        "    y_pred_train = hyperFT_model.predict(X_train)\n",
        "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Perform cross-validation on the training set and calculate the mean accuracy\n",
        "    cv_test_accuracy = cross_val_score(hyperFT_model, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
        "    cv_test_accuracies.append(cv_test_accuracy)\n",
        "\n",
        "# Plot the performance metrics\n",
        "plt.figure(figsize=(9, 5))  # Adjust figure size as needed\n",
        "plt.plot(n_neighbors_range, train_accuracies, label='Train Accuracy', marker='o', color='blue')\n",
        "plt.plot(n_neighbors_range, cv_test_accuracies, label='Mean Cross-Validated Test Accuracy', marker='o', color='green')\n",
        "\n",
        "plt.xlabel('Number of Neighbors (k)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Performance of k-NN with Varying Number of Neighbors')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "etepOrHz0erC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Displaying the best hyperparameter combinations based on mean CV accuracy"
      ],
      "metadata": {
        "id": "sVa_GPv1O674"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "\n",
        "hyperBC_model = KNeighborsClassifier()\n",
        "\n",
        "# Define the hyperparameters to tune\n",
        "parameters = {\n",
        "    'n_neighbors': [8, 11, 13, 15],      # Number of neighbors to consider\n",
        "    'weights': ['uniform', 'distance'],  # Weight used in prediction\n",
        "    'metric': ['euclidean'] # Distance metric for the tree\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV with cross-validation (e.g., cv=5)\n",
        "grid_knn = GridSearchCV(hyperBC_model, param_grid=parameters, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_knn.fit(X_train, y_train)\n",
        "\n",
        "# Create a DataFrame to display the results\n",
        "result = pd.DataFrame(grid_knn.cv_results_['params'])\n",
        "result['mean_CV_test_score'] = grid_knn.cv_results_['mean_test_score']\n",
        "result = result.sort_values(by='mean_CV_test_score', ascending=False)\n",
        "\n",
        "# Display the sorted DataFrame of hyperparameter combinations and their CV scores\n",
        "result\n"
      ],
      "metadata": {
        "id": "exBICaeL7T4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now let's fine-tune with the best hyperparameters combined"
      ],
      "metadata": {
        "id": "ghw4gVwPPSng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the Tuned k-NN Model (with best hyperparameters)\n",
        "tuned_knn_model = KNeighborsClassifier(n_neighbors=13, weights='distance', metric='euclidean')\n",
        "tuned_knn_model.fit(X_train, y_train)\n",
        "y_pred_tuned = tuned_knn_model.predict(X_test)\n",
        "\n",
        "tuned_knn_model"
      ],
      "metadata": {
        "id": "bFP8XS3ixZCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare Performance: Original vs Tuned KNN"
      ],
      "metadata": {
        "id": "CE0ONKkFRBaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate performance metrics for our original model\n",
        "train_accuracy_original = knn_model.score(X_train, y_train)\n",
        "test_accuracy_original = accuracy_score(y_test, y_pred)\n",
        "precision_original = precision_score(y_test, y_pred)\n",
        "recall_original = recall_score(y_test, y_pred)\n",
        "f1_original = f1_score(y_test, y_pred)\n",
        "confusion_matrix_original = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calculate Performance Metrics for the Tuned k-NN Model\n",
        "train_accuracy_tuned = tuned_knn_model.score(X_train, y_train)\n",
        "test_accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
        "precision_tuned = precision_score(y_test, y_pred_tuned)\n",
        "recall_tuned = recall_score(y_test, y_pred_tuned)\n",
        "f1_tuned = f1_score(y_test, y_pred_tuned)\n",
        "confusion_matrix_tuned = confusion_matrix(y_test, y_pred_tuned)\n",
        "\n",
        "# Create a Comparison Table for Evaluation Metrics\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Evaluation Metric': ['Train Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
        "    'Original k-NN': [train_accuracy_original, test_accuracy_original, precision_original, recall_original, f1_original],\n",
        "    'Tuned k-NN': [train_accuracy_tuned, test_accuracy_tuned, precision_tuned, recall_tuned, f1_tuned]\n",
        "})\n",
        "\n",
        "# Set precision for floating point numbers\n",
        "pd.set_option(\"display.precision\", 4)\n",
        "\n",
        "# Display the comparison table\n",
        "display(comparison_df)"
      ],
      "metadata": {
        "id": "8ODWrQCLQ7oA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))  # Adjust figure size as needed\n",
        "\n",
        "# Plot Confusion Matrix for Original k-NN Model\n",
        "sns.heatmap(confusion_matrix_original, annot=True, fmt='d', cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names, ax=axes[0])\n",
        "axes[0].set_title('Original k-NN', fontsize=14)\n",
        "axes[0].set_xlabel('Predicted Class', fontsize=12)\n",
        "axes[0].set_ylabel('True Class', fontsize=12)\n",
        "\n",
        "# Plot Confusion Matrix for Tuned k-NN Model\n",
        "sns.heatmap(confusion_matrix_tuned, annot=True, fmt='d', cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names, ax=axes[1])\n",
        "axes[1].set_title('Tuned k-NN', fontsize=14)\n",
        "axes[1].set_xlabel('Predicted Class', fontsize=12)\n",
        "axes[1].set_ylabel('')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-FBTYUDfBCVM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}