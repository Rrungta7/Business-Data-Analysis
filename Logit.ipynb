{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umhXv_xigpOf"
      },
      "outputs": [],
      "source": [
        "# For data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# For model training and evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.model_selection as ms\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# For visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import Image\n",
        "import pydotplus\n",
        "%matplotlib inline\n",
        "\n",
        "# For Google Colab integration\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import data as dataframe\n",
        "file_path = '/content/drive/MyDrive/Infor648/Data/churn.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# calling head() method\n",
        "df.head()"
      ],
      "metadata": {
        "id": "-ySD4QfzJ1nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df.isna().sum()) ##check missing value\n",
        "df = df.dropna() ##drop missing value"
      ],
      "metadata": {
        "id": "d6vBQImeNIpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df.isna().sum()) ##recheck missing value again"
      ],
      "metadata": {
        "id": "61neLslTNMd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numeric Variables\n",
        "numeric_variables = [col for col in df.columns if df[col].dtype != \"object\" and col not in \"Customer Status\"] ##exclude our target variable: customer status\n",
        "numeric_variables"
      ],
      "metadata": {
        "id": "vm26EbrSNuDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Examine correlation among independent variables"
      ],
      "metadata": {
        "id": "tc3f3t260wjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test  = df[[\"Age\", \"Number of Dependents\",\"Total Charges\",\"Monthly Charge\",\"Total Refunds\", \"Tenure in Months\", \"Number of Referrals\"]]"
      ],
      "metadata": {
        "id": "DDaeHIABONQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = df_test.corr()\n",
        "plt.figure(figsize=(5,5)) ###change the figure size here\n",
        "sns.heatmap(corr_matrix, cmap='Blues', annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mwpnhU8POYPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multicollinearity check"
      ],
      "metadata": {
        "id": "CS13d7eX628o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VIF stands for Variance Inflation Factor, measures how much the variance of a regression coefficient is inflated due to multicollinearity with other variables in the model.\n",
        "\n",
        "It is used to detect the presence of multicollinearity in a regression analysis. Multicollinearity occurs when two or more predictor variables (independent variables) in a regression model are highly correlated, meaning that they provide redundant information and affect the reliability of the regression coefficients."
      ],
      "metadata": {
        "id": "siBh3OwDa_SO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VIF = 1: No multicollinearity. The predictor is not correlated with any other variables.\n",
        "\n",
        "VIF between 1 and 5: Moderate multicollinearity. Generally acceptable, though closer to 5 might be a concern.\n",
        "\n",
        "VIF > 5: High multicollinearity. The predictor is highly correlated with other predictors, which may affect the reliability of the coefficient estimates.\n",
        "\n",
        "VIF > 10: Severe multicollinearity. The predictor is very highly correlated with other variables, and steps should be taken to reduce multicollinearity (e.g., removing one of the correlated variables)."
      ],
      "metadata": {
        "id": "ypek-MH_bpo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# VIF dataframe\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = df_test.columns\n",
        "\n",
        "# calculating VIF for each feature\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(df_test.values, i)\n",
        "                          for i in range(len(df_test.columns))]\n",
        "\n",
        "print(vif_data)"
      ],
      "metadata": {
        "id": "HGI9as0hPAN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_2 = df[[\"Age\", \"Number of Dependents\",\"Monthly Charge\",\"Total Refunds\", \"Tenure in Months\", \"Number of Referrals\"]]\n",
        "# VIF dataframe\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"feature\"] = df_test_2.columns\n",
        "\n",
        "# calculating VIF for each feature\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(df_test_2.values, i)\n",
        "                          for i in range(len(df_test_2.columns))]\n",
        "\n",
        "print(vif_data)"
      ],
      "metadata": {
        "id": "RFz_UNFHPQCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Select our features and our target variable"
      ],
      "metadata": {
        "id": "NhG6VcSE08M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub = df[[\"Age\", \"Number of Dependents\",\"Monthly Charge\",\"Total Refunds\", \"Tenure in Months\", \"Number of Referrals\", \"Customer Status\"]]"
      ],
      "metadata": {
        "id": "BwMywJ7JPWde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "####We are only interested in why people stayed and churned\n",
        "df_sub = df_sub[df_sub['Customer Status'] !='Joined'] # we drop all the new customers\n",
        "\n",
        "####Encode our target variable\n",
        "target_label_encoder = LabelEncoder()\n",
        "df_sub['Customer Status'] = target_label_encoder.fit_transform(df_sub['Customer Status'])\n",
        "\n",
        "\n",
        "##display the stats after encoding\n",
        "display(df_sub['Customer Status'].value_counts())\n",
        "mapping = dict(zip(target_label_encoder.classes_, target_label_encoder.transform(target_label_encoder.classes_)))\n",
        "print(mapping)"
      ],
      "metadata": {
        "id": "xfXvFo5qQPbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define features (X) and target (y)"
      ],
      "metadata": {
        "id": "7eD4x79U8Udd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "X = df_sub.drop('Customer Status', axis=1)  # Drop the target column to get independent variables\n",
        "y = df_sub['Customer Status']  # Select the target column directly as our y\n",
        "\n",
        "feature_names = X.columns.tolist()\n",
        "\n",
        "\n",
        "\n",
        "class_names = target_label_encoder.inverse_transform(np.arange(len(target_label_encoder.classes_)))\n",
        "\n",
        "##print out the features we selected for predictions and our classification target\n",
        "print(\"features:\",feature_names)\n",
        "print(\"Classes:\", class_names)"
      ],
      "metadata": {
        "id": "-WJipLP4QbS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the independent variables\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "# Split the dataset into training and testing sets (70% training, 30% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
      ],
      "metadata": {
        "id": "Ck90mEhWQf6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train our logit model"
      ],
      "metadata": {
        "id": "kI7VDoO38bvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Logistic Regression model\n",
        "logistic_model = LogisticRegression()\n",
        "logistic_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = logistic_model.predict(X_test)\n",
        "\n",
        "\n",
        "# Create a DataFrame for evaluation metrics\n",
        "evaluation_metrics = pd.DataFrame({\n",
        "    \"Evaluation Metric\": [\"Train Accuracy\", \"Test Accuracy\", \"Recall\", \"Precision\", \"F1 Score\"],\n",
        "    \"Value\": [\n",
        "        logistic_model.score(X_train, y_train),\n",
        "        accuracy_score(y_test, y_pred),\n",
        "        recall_score(y_test, y_pred),\n",
        "        precision_score(y_test, y_pred),\n",
        "        f1_score(y_test, y_pred)\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Display the DataFrame with evaluation metrics\n",
        "print(\"Logistic Regression Evaluation Metrics:\")\n",
        "display(evaluation_metrics)\n"
      ],
      "metadata": {
        "id": "lbdmg84qQkQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix using seaborn\n",
        "plt.figure(figsize=(8, 6))  # Adjust figure size if needed\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.ylabel('True Class')\n",
        "plt.xlabel('Predicted Class')\n",
        "plt.title('Confusion Matrix for Logistic Regression Model')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RCEa2MVBXdzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.classifier import ClassificationReport\n",
        "\n",
        "# Create the classification report visualizer for the Logistic Regression model\n",
        "visualizer = ClassificationReport(logistic_model, classes=class_names, support=False, title=\"Logistic Regression Classifier Evaluation\")\n",
        "\n",
        "# Fit the visualizer\n",
        "visualizer.fit(X_train, y_train)\n",
        "visualizer.score(X_test, y_test)\n",
        "\n",
        "# Display the plot\n",
        "visualizer.show()\n"
      ],
      "metadata": {
        "id": "Rf0VVw8_Xha-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#This method provides a more detailed statistical summary, including p-values and other key metrics."
      ],
      "metadata": {
        "id": "NZD0t7K-lIyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Logistic Regression model using statsmodels\n",
        "model_sm = sm.Logit(y_train, X_train)\n",
        "results = model_sm.fit(method=\"newton\")\n",
        "\n",
        "# Create a summary with the feature names\n",
        "features = feature_names\n",
        "print(results.summary2(xname=features))\n",
        "\n",
        "\n",
        "###Use P-value for statistically significant\n",
        "##LLR p-value is the overall significance of the logit regression model\n",
        "##p-value for each feauture is the feature significance for prediction\n",
        "##p-value <0.01 <0.05 <0.10 if p-value >= 0.10 no evidence of stats significant\n",
        "##LL-null is the baseline reference model\n",
        "##R^2 how much better the model performs"
      ],
      "metadata": {
        "id": "uN7857ahQoZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the coefficients for each feature\n",
        "coefficients = logistic_model.coef_[0]\n",
        "\n",
        "# Create a DataFrame to display the feature names and their corresponding coefficients\n",
        "feature_impact = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefficients,\n",
        "    'Odds Ratio': np.exp(coefficients)   # Convert odds ratios using the exponential function (e^x)\n",
        "})\n",
        "\n",
        "feature_impact = feature_impact.sort_values(by='Odds Ratio', ascending=False)\n",
        "display(feature_impact)"
      ],
      "metadata": {
        "id": "F8SvVAcBam7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "\n",
        "model_cv = LogisticRegression()\n",
        "\n",
        "# Perform cross-validation and get aggregated predictions\n",
        "y_pred_cross = cross_val_predict(model_cv, X, y, cv=10)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy_cv = accuracy_score(y, y_pred_cross)\n",
        "recall_cv = recall_score(y, y_pred_cross)\n",
        "precision_cv = precision_score(y, y_pred_cross)\n",
        "f1_cv = f1_score(y, y_pred_cross)\n",
        "matrix_cv = confusion_matrix(y, y_pred_cross)\n",
        "\n",
        "# Create a DataFrame for evaluation metrics with cross-validation\n",
        "evaluation_metrics_cv = pd.DataFrame({\n",
        "    \"Evaluation Metric\": [\"Accuracy\", \"Recall\", \"Precision\", \"F1 Score\"],\n",
        "    \"Value\": [accuracy_cv, recall_cv, precision_cv, f1_cv]\n",
        "})\n",
        "\n",
        "print(\"Performance Metrics With Cross-Validation:\")\n",
        "display(evaluation_metrics_cv)\n",
        "\n",
        "\n",
        "print(\"\\nConfusion Matrix - Cross Validation:\\n\", matrix_cv)\n",
        "\n",
        "\n",
        "\n",
        "# Display the evaluation metrics without CV\n",
        "print(\"\\nLogistic Regression Evaluation Metrics without CV:\")\n",
        "display(evaluation_metrics)\n",
        "print(\"\\nConfusion Matrix - Without CV:\\n\", conf_matrix)\n",
        "\n"
      ],
      "metadata": {
        "id": "G3U0WtZ4YuQw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}