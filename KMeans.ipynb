{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "##install the pywaffle package for visualization\n",
        "!pip install pywaffle matplotlib"
      ],
      "metadata": {
        "id": "dh_G0JM0VCNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfX0O_FG10gC"
      },
      "outputs": [],
      "source": [
        "# For Google Colab integration\n",
        "import os\n",
        "from google.colab import drive\n",
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# For data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import data as dataframe\n",
        "file_path = '/content/drive/MyDrive/Infor648/Data/Mall_Customers.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "# calling head() method\n",
        "df.head()"
      ],
      "metadata": {
        "id": "17_qmAzc2fNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Select variables of interest"
      ],
      "metadata": {
        "id": "_XJsziQn-t2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub= df[['Annual Income (k$)', 'Spending Score (1-100)']]"
      ],
      "metadata": {
        "id": "SUFP3m084ho3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Scatter Plot of Selected Variables (only for two variables)\n",
        "## Note: This scatter plot is two-dimensional, as it visualizes the relationship between two variables.\n"
      ],
      "metadata": {
        "id": "dp4L-SuO__qF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Plotting the features\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df_sub['Annual Income (k$)'], df_sub['Spending Score (1-100)'], c='blue', label='Customer')\n",
        "\n",
        "\n",
        "plt.xlabel('Annual Income (k$)')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "plt.title('Scatter Plot of Original Data')\n",
        "plt.legend()\n",
        "plt.grid(False)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AiJX33dd9XiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalize the data (or Standardize if needed)"
      ],
      "metadata": {
        "id": "DuJ9U8KzAj1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# data normalization\n",
        "norm_scaler = MinMaxScaler()\n",
        "data_norm = norm_scaler.fit_transform(df_sub)\n",
        "##data_norm is the normalized data"
      ],
      "metadata": {
        "id": "XiZVy2BR989O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the independent variables\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "std_scaler = StandardScaler()\n",
        "data_std = std_scaler.fit_transform(df_sub)\n",
        "##data_std is the normalized data"
      ],
      "metadata": {
        "id": "RWGr1Mz-9iTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform clustering on the selected variables\n"
      ],
      "metadata": {
        "id": "7OewMrhrBBYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "### n_clusters: Specifies the number of clusters to form, which is 5 in this case\n",
        "### init: The method for initialization, 'k-means++' ensures better initial centroids\n",
        "### n_init: Number of times it performs clustering with different initializations of centroids, and chooses the best result (lowest sum of squared distances)\n",
        "\n",
        "### random_state: Ensures reproducibility of the results by fixing the random number generator\n",
        "\n",
        "model = KMeans(n_clusters = 7, init = 'k-means++', n_init = 10, random_state = 1)\n",
        "model.fit(data_norm)\n",
        "df_sub['cluster'] = model.fit_predict(data_norm)"
      ],
      "metadata": {
        "id": "Z2tfJnAv4oKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plot the clusters (only for two variables)"
      ],
      "metadata": {
        "id": "SDdMt342BIzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the clusters\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df_sub['Annual Income (k$)'], df_sub['Spending Score (1-100)'], c=df_sub['cluster'], cmap='viridis', label='Customer')\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Annual Income (k$)')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "plt.title('K-means Clustering')\n",
        "plt.colorbar(label='Cluster')\n",
        "\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ruwUpcWrDors"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#looks for the point where the decrease in WCSS becomes insignificant relative to the previous clusters. Adding more clusters doesnâ€™t significantly improve the fit."
      ],
      "metadata": {
        "id": "7ws-hBI9IVUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List to store WCSS (within-cluster sum of squares)\n",
        "wcss = []\n",
        "\n",
        "# Compute WCSS for a range of cluster numbers (1 to 10), you can change the number here if it is needed\n",
        "for i in range(1, 11):###change here\n",
        "    kmeans_WCSS = KMeans(n_clusters=i, init='k-means++', n_init=10, random_state=1)\n",
        "    kmeans_WCSS.fit(data_norm)\n",
        "    wcss.append(kmeans_WCSS.inertia_)\n",
        "\n",
        "# Plot the elbow curve\n",
        "plt.figure(figsize=(8, 6)) #Adjust figure size here\n",
        "plt.plot(range(1, 11), wcss, marker='o')##adjust your selection of k range here to make it shows on plot\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fovJy3fh4rxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#A straightforward way to help you find the best k\n",
        "\n",
        "##Distortion score is WCSS\n",
        "##WCSS focus on minimizing the variance within clusters (intra-cluster compactness)\n"
      ],
      "metadata": {
        "id": "cFF_r57sBxUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Initialize the KMeans model with same parameters\n",
        "model_Elbow = KMeans(init='k-means++', n_init=10, random_state=1)\n",
        "\n",
        "# Initialize the visualizer with the number of clusters to explore starting from 2, k=1 does not provide meaningful infor\n",
        "visualizer = KElbowVisualizer(model_Elbow, k=(2, 10)) #You can adjust the k value here\n",
        "\n",
        "\n",
        "visualizer.fit(data_norm)\n",
        "\n",
        "# Display the elbow plot\n",
        "visualizer.show()\n",
        "\n",
        "##distortion score is WCSS\n"
      ],
      "metadata": {
        "id": "i0ZQiyV8GmVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Use Silouette score (can give you different optimal K)\n",
        "##Silouett score look at both compactness(cohesion) and how well-seperate (separation) from each other. If clusters are close to each other, it might suggest few clusters\n",
        "\n",
        "\n",
        "\n",
        "##WCSS focus on minimizing the variance within clusters (intra-cluster compactness). It might suggests more clusters"
      ],
      "metadata": {
        "id": "qvUbHNgxDq-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Initialize the KMeans model with the same parameters\n",
        "model_sil = KMeans(init='k-means++', n_init=10, random_state=1)\n",
        "\n",
        "\n",
        "# Set the metric to 'silhouette' instead of the default 'distortion' (WCSS)\n",
        "# Initialize the visualizer with the number of clusters to explore (start from 2)\n",
        "visualizer = KElbowVisualizer(model_sil, k=(2, 10), metric='silhouette') ##you can change the value of k here\n",
        "\n",
        "\n",
        "visualizer.fit(data_norm)\n",
        "\n",
        "# Display the elbow plot with silhouette score\n",
        "visualizer.show()\n"
      ],
      "metadata": {
        "id": "tSsqTq4SLD0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now we refine our model"
      ],
      "metadata": {
        "id": "XCppqpdiIWdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimal_k = 5  # Replace with the number of clusters determined from the Elbow Method\n",
        "kmeans_optimal= KMeans(n_clusters=optimal_k, init='k-means++', n_init=10, random_state=1)\n",
        "\n",
        "df_sub['cluster'] = kmeans_optimal.fit_predict(data_norm)\n"
      ],
      "metadata": {
        "id": "wfC6KeSl4-80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the silhouette score for the fitted model\n",
        "silhouette_avg = silhouette_score(data_norm, df_sub['cluster'])\n",
        "# Print the silhouette score\n",
        "print(f'\\nSilhouette Score for k={optimal_k}: {silhouette_avg}\\n')\n",
        "\n",
        "\n",
        "visualizer = SilhouetteVisualizer(kmeans_optimal, colors='yellowbrick')\n",
        "visualizer.fit(data_norm)\n",
        "visualizer.show()"
      ],
      "metadata": {
        "id": "ZcKsXs_nEqBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the clusters\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(df_sub['Annual Income (k$)'], df_sub['Spending Score (1-100)'], c=df_sub['cluster'], cmap='viridis', label='Customer')\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Annual Income (k$)')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "plt.title('K-means Clustering (Original Data)')\n",
        "plt.colorbar(label='Cluster')\n",
        "\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CEb8_1TfEE4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualize the cluster"
      ],
      "metadata": {
        "id": "QTBZcDIzGezx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sub"
      ],
      "metadata": {
        "id": "HFpC0UEMaKVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_counts = df_sub['cluster'].value_counts()  # Get the counts for each cluster\n",
        "total = cluster_counts.sum()  # Get the total number of data points\n",
        "\n",
        "# Create a DataFrame to hold both counts and percentages\n",
        "cluster_summary = pd.DataFrame({\n",
        "    'Count': cluster_counts,\n",
        "    'Percentage': round((cluster_counts / total) * 100, 2)  # Calculate percentage and round to 2 decimal places\n",
        "})\n",
        "\n",
        "# Display the table\n",
        "display(cluster_summary)"
      ],
      "metadata": {
        "id": "XP0gdVedYPrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pywaffle import Waffle\n",
        "\n",
        "\n",
        "cluster_counts = df_sub['cluster'].value_counts()\n",
        "total = sum(cluster_counts)\n",
        "\n",
        "# Plot the waffle chart with percentages added to the labels\n",
        "fig = plt.figure(\n",
        "    FigureClass=Waffle,\n",
        "    rows=5,  # Number of rows in the waffle chart, you can adjust here\n",
        "    values=cluster_counts,  # Values for each cluster\n",
        "    title={'label': 'Cluster Distribution KMeans', 'loc': 'center'},\n",
        "    labels=[f\"Cluster {i} ({count} - {round((count / total) * 100, 2)}%)\" for i, count in cluster_counts.items()],\n",
        "    legend={'loc': 'upper left', 'bbox_to_anchor': (1, 1.2)}, #You can also adjust the number to adjust the legend location\n",
        "    figsize=(8, 5) #adjust figure size\n",
        ")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7nr8e4q-U7qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#We need to understand the detailed stats inside each cluster\n"
      ],
      "metadata": {
        "id": "ekYvrZBsHjI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####You do not need to change anything here just run it to enable the generate_cluster_profile function#########\n",
        "def generate_cluster_profile(data_norm, k, df_original):\n",
        "\n",
        "    # Apply KMeans clustering\n",
        "    kmeans_optimal = KMeans(n_clusters=k, init='k-means++', n_init=10, random_state=1)\n",
        "    df_sub = df_original.copy()\n",
        "    df_sub['cluster'] = kmeans_optimal.fit_predict(data_norm)\n",
        "\n",
        "    # Create a copy of the DataFrame for calculations\n",
        "    df_calculate = df_sub.copy()\n",
        "    df_calculate['cluster_result'] = 'Cluster ' + (df_calculate['cluster']).astype(str)\n",
        "\n",
        "    # Exclude the 'cluster' column for mean calculation\n",
        "    df_mean_calculation = df_calculate.drop(columns=['cluster'])\n",
        "    df_mean_feature = df_mean_calculation.drop(columns=['cluster_result'])  # Exclude 'cluster_result' column for overall mean\n",
        "\n",
        "    # Calculate Overall Mean for All Features in df_mean_feature\n",
        "    overall_means = df_mean_feature.mean().to_frame().T\n",
        "    overall_means.index = ['Overall']\n",
        "\n",
        "    # Summarize Mean of Each Cluster\n",
        "    df_cluster_summary = df_mean_calculation.groupby('cluster_result').mean()\n",
        "\n",
        "    # Add Overall Mean Row to Cluster Summary\n",
        "    df_profile = pd.concat([df_cluster_summary, overall_means], axis=0)\n",
        "\n",
        "    # Calculate the count of items in each cluster\n",
        "    cluster_counts = df_calculate['cluster_result'].value_counts()\n",
        "\n",
        "    # Calculate the percentage of items in each cluster\n",
        "    cluster_percentages = (cluster_counts / cluster_counts.sum()) * 100\n",
        "\n",
        "    # Create a DataFrame with counts and percentages\n",
        "    df_count_percentage = pd.DataFrame({\n",
        "        'Count': cluster_counts,\n",
        "        'Percentage': cluster_percentages\n",
        "    })\n",
        "\n",
        "    # Add a row for \"Overall\"\n",
        "    df_count_percentage.loc['Overall'] = [len(df_calculate), 100.0]\n",
        "    df_profile = pd.concat([df_profile, df_count_percentage], axis=1)\n",
        "    df_overall = df_profile.loc['Overall']\n",
        "    df_profile = df_profile.drop(index='Overall')\n",
        "\n",
        "    # Sort the clusters by the Count column\n",
        "    df_profile = df_profile.sort_values(by='Count', ascending=False)\n",
        "\n",
        "    # Append the \"Overall\" row back to the sorted DataFrame\n",
        "    df_profile = pd.concat([df_profile, df_overall.to_frame().T])\n",
        "\n",
        "    # Format the profile DataFrame\n",
        "    df_profile = df_profile.style.format({\n",
        "        \"Count\": \"{:.0f}\",\n",
        "        **{col: \"{:.2f}\" for col in df_profile.columns if col != \"Count\"}  # Two decimal places for all other columns\n",
        "    }).background_gradient(cmap='Purples')\n",
        "\n",
        "    return df_profile\n",
        "\n"
      ],
      "metadata": {
        "id": "zFd-URgrg6Wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#To generate the cluster profile call the function"
      ],
      "metadata": {
        "id": "aLeBy_bldZCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### change the number for k right now k is 5\n",
        "##data_norm is our normalized data we call it data_norm\n",
        "##df_sub is our select variables of interest\n",
        "\n",
        "df_profile_k5 = generate_cluster_profile(data_norm, 5, df_sub) ##change the number here for k value\n",
        "display(df_profile_k5)"
      ],
      "metadata": {
        "id": "J_YLszpRelpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lets compare k = 5 and k = 4"
      ],
      "metadata": {
        "id": "9BbUmSxFHCh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# K-means model with k=5 clusters, adjust n_clusters\n",
        "model_1 = KMeans(n_clusters=5, init='k-means++', random_state=1) ##adjust cluster value\n",
        "model_1.fit(data_norm)\n",
        "visualizer = SilhouetteVisualizer(model, colors='yellowbrick')\n",
        "visualizer.fit(data_norm)  # data_norm is your normalized dataset\n",
        "\n",
        "# Calculate and display the average silhouette score\n",
        "avg_silhouette_5 = silhouette_score(data_norm, model_1.labels_)\n",
        "print(f\"Average Silhouette Score for k=5: {avg_silhouette_5:.3f}\")\n",
        "visualizer.show()  # Display the silhouette plot\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# K-means model with k=4 clusters for comparison\n",
        "model_2 = KMeans(n_clusters=4, init='k-means++', random_state=1) ###adjust cluster value\n",
        "model_2.fit(data_norm)\n",
        "visualizer_2 = SilhouetteVisualizer(model, colors='yellowbrick')\n",
        "visualizer_2.fit(data_norm)  # data_norm is your normalized dataset\n",
        "\n",
        "# Calculate and display the average silhouette score\n",
        "avg_silhouette_4 = silhouette_score(data_norm, model_2.labels_)\n",
        "print(f\"Average Silhouette Score for k=4: {avg_silhouette_4:.3f}\")\n",
        "\n",
        "visualizer_2.show()  # Display the silhouette plot\n",
        "\n"
      ],
      "metadata": {
        "id": "uWmFmAmjPFdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###call the generate_cluster_profile function to compare\n",
        "\n",
        "df_profile_k4 = generate_cluster_profile(data_norm, 4, df_sub)\n",
        "df_profile_k5 = generate_cluster_profile(data_norm, 5, df_sub)\n",
        "\n",
        "display(df_profile_k4)\n",
        "print()\n",
        "display(df_profile_k5)"
      ],
      "metadata": {
        "id": "n3ByL8uCaEIn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}